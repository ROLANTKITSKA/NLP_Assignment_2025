{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62adfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0697eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "original1 = \"Thank your message to show our words to the doctor, as his next contract checking, to all of us.\"\n",
    "reconstructed1 = \"Thank your note to show our words to the supervisor, as his next agreement checking, to all of us.\"\n",
    "original2 = \"Also, kindly remind me please, if the doctor still plan for the acknowledgments section edit before he sending again.\"\n",
    "reconstructed2 = \"Also, kindly let me know me please, if the supervisor still intend for the thank you note part change before he sends it again.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fa395eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [original1, reconstructed1, original2, reconstructed2]\n",
    "tokenized_sentences = [simple_preprocess(s) for s in sentences]\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6be3f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_similarity(words1, words2, model):\n",
    "    similarities = []\n",
    "    for w1 in words1:\n",
    "        if w1 in model.wv:\n",
    "            max_sim = max([\n",
    "                cosine_similarity([model.wv[w1]], [model.wv[w2]])[0][0]\n",
    "                for w2 in words2 if w2 in model.wv\n",
    "            ], default=0)\n",
    "            similarities.append(max_sim)\n",
    "    return np.mean(similarities) if similarities else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2517cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_sentences(original, reconstructed):\n",
    "    tokens1 = simple_preprocess(original)\n",
    "    tokens2 = simple_preprocess(reconstructed)\n",
    "    sim1 = average_similarity(tokens1, tokens2, model)\n",
    "    sim2 = average_similarity(tokens2, tokens1, model)\n",
    "    return (sim1 + sim2) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69e0236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score (original1 vs reconstructed1): 0.8700\n",
      "Similarity score (original2 vs reconstructed2): 0.6652\n"
     ]
    }
   ],
   "source": [
    "similarity_1 = compare_sentences(original1, reconstructed1)\n",
    "similarity_2 = compare_sentences(original2, reconstructed2)\n",
    "print(f\"Similarity score (original1 vs reconstructed1): {similarity_1:.4f}\")\n",
    "print(f\"Similarity score (original2 vs reconstructed2): {similarity_2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
